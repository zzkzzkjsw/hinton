{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import wandb\n",
    "\n",
    "from d2l import torch as d2l\n",
    "\n",
    "from my_config import Config\n",
    "from my_utils import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzzk5678\u001b[0m (\u001b[33mzzkzzkjsw\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/book/D/notes/d2l-zh/pytorch/wandb/run-20231208_124959-dft01lyo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/zzkzzkjsw/lenet/runs/dft01lyo' target=\"_blank\">fast-snowflake-12</a></strong> to <a href='https://wandb.ai/zzkzzkjsw/lenet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/zzkzzkjsw/lenet' target=\"_blank\">https://wandb.ai/zzkzzkjsw/lenet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/zzkzzkjsw/lenet/runs/dft01lyo' target=\"_blank\">https://wandb.ai/zzkzzkjsw/lenet/runs/dft01lyo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "config = Config()\n",
    "config.train.device = device\n",
    "wandb.init(project=\"lenet\", config=config)\n",
    "\n",
    "set_seed(config.train.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = torchvision.datasets.FashionMNIST('./data',train=True,transform=torchvision.transforms.ToTensor(),download=True)\n",
    "mnist_test = torchvision.datasets.FashionMNIST('./data',train=False,transform=torchvision.transforms.ToTensor(),download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    # batch is a list, each element is a (X,y) pair from dataset\n",
    "    # in Minist dataset, X is a tensor, y is a integer\n",
    "    xs = torch.stack([item[0] for item in batch])\n",
    "    ys = torch.tensor([item[1] for item in batch], dtype=torch.long)  # 将 y 列表转换为张量\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = DataLoader(mnist_train, batch_size=config.train.batch_size, shuffle=config.data.shuffle, num_workers=config.data.num_workers, collate_fn=custom_collate_fn)\n",
    "test_iter = DataLoader(mnist_test, batch_size=config.train.batch_size, shuffle=False, num_workers=config.data.num_workers, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, out_dim=10, pooling='avg'):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,kernel_size=5,padding=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(6,16,kernel_size=5)\n",
    "        if(pooling=='avg'):\n",
    "            self.pooling = nn.MaxPool2d(2)\n",
    "        elif(pooling=='max'):\n",
    "            self.pooling = nn.AvgPool2d(2)\n",
    "        self.lin1 = nn.Linear(400,128)\n",
    "        self.lin2 = nn.Linear(128,out_dim)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        assert list(x.shape) == [bsz, 1, 28, 28]\n",
    "        x = self.relu(self.conv1(x))\n",
    "        assert list(x.shape) == [bsz, 6, 28, 28]\n",
    "        x = self.pooling(x)\n",
    "        assert list(x.shape) == [bsz, 6, 14, 14]\n",
    "        x = self.relu(self.conv2(x))\n",
    "        assert list(x.shape) == [bsz, 16, 10, 10]\n",
    "        x = self.pooling(x)\n",
    "        assert list(x.shape) == [bsz, 16, 5, 5]\n",
    "        x = x.reshape(bsz, -1)\n",
    "        assert list(x.shape) == [bsz, 400]\n",
    "        x = self.relu(self.lin1(x))\n",
    "        assert list(x.shape) == [bsz, 128]\n",
    "        x = self.lin2(x)\n",
    "        assert list(x.shape) == [bsz, 10]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),\n",
    "    nn.Linear(120, 84), nn.Sigmoid(),\n",
    "    nn.Linear(84, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(),lr=config.train.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y):\n",
    "    return (y_pred.argmax(-1)==y).sum()/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "net.apply(init_weights)\n",
    "\n",
    "for epoch in range(config.train.num_epochs):\n",
    "    device = config.train.device\n",
    "    net.train()\n",
    "    for idx,(X,y) in enumerate(train_iter):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        X,y = X.to(device), y.to(device)\n",
    "        y_pred = net(X)\n",
    "        l = loss(y_pred,y)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            acc = accuracy(y_pred, y)\n",
    "            wandb.log({\"Iteration loss\":l,\"acc\":acc, \"idx\":idx, \"epoch\":epoch})\n",
    "\n",
    "        l.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(),10.0)\n",
    "        optimizer.step()\n",
    "\n",
    "    net.eval()\n",
    "    for X,y in test_iter:\n",
    "        with torch.no_grad():\n",
    "            X,y = X.to(device), y.to(device)\n",
    "            y_pred = net(X)\n",
    "            test_acc = accuracy(y_pred, y)\n",
    "            wandb.log({\"test_acc\":acc, \"idx\":idx, \"epoch\":epoch})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
